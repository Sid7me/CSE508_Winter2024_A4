{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8194274,"sourceType":"datasetVersion","datasetId":4853343},{"sourceId":8198719,"sourceType":"datasetVersion","datasetId":4856710},{"sourceId":8248276,"sourceType":"datasetVersion","datasetId":4893809}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-30T21:25:06.434212Z","iopub.execute_input":"2024-04-30T21:25:06.434965Z","iopub.status.idle":"2024-04-30T21:25:06.450708Z","shell.execute_reply.started":"2024-04-30T21:25:06.434932Z","shell.execute_reply":"2024-04-30T21:25:06.449819Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/kaggle/input/reviews/preprocessed_reviews.csv\n/kaggle/input/modelpath/fine_tuned_model.pth\n/kaggle/input/modelxx/modelxx.pth\n/kaggle/input/models/gpt2_024.pth\n/kaggle/input/models/fine_tuned_newmodel.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\n\nclass Custom_class(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        review_text = self.data['Text'].iloc[index]\n        summary_text = self.data['Summary'].iloc[index]\n        \n        review_tokens = self.tokenize_and_pad(review_text)\n        summary_tokens = self.tokenize_and_pad(summary_text)\n        \n        return {'input_ids': torch.tensor(review_tokens), 'labels': torch.tensor(summary_tokens)}\n    \n    def tokenize_and_pad(self, text):\n        tokens = self.tokenizer.encode(text, max_length=self.max_length, truncation=True)\n        padded_tokens = tokens[:self.max_length] + [0] * (self.max_length - len(tokens))\n        return padded_tokens\n\n\ndf = pd.read_csv(\"/kaggle/input/reviews/preprocessed_reviews.csv\")  \ntrain_df = df.sample(n=1000, random_state=42)  \n\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\ntrain_dataset = Custom_class(train_df, tokenizer, max_length=512)\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nmodel.train()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.9)\n\nnum_epochs = 5\nepoch = 0\nwhile epoch < num_epochs:\n    total_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n        \n        outputs = model(input_ids=input_ids, labels=labels)\n        loss = outputs.loss\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += loss.item()\n    \n    avg_loss = total_loss / len(train_loader)\n    print(f\"Avg Loss: {avg_loss:.4f}\")\n    \n    epoch += 1\n\ntorch.save(model.state_dict(), \"./fine_tuned_newmodel.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T01:27:45.862983Z","iopub.execute_input":"2024-04-23T01:27:45.863747Z","iopub.status.idle":"2024-04-23T01:41:20.164677Z","shell.execute_reply.started":"2024-04-23T01:27:45.863710Z","shell.execute_reply":"2024-04-23T01:41:20.163527Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 500/500 [02:41<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0845\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 500/500 [02:41<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0621\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 500/500 [02:41<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0592\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 500/500 [02:41<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0575\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 500/500 [02:41<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0546\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        review_text = self.data['Text'].iloc[index]\n        summary_text = self.data['Summary'].iloc[index]\n        \n        review_tokens = self.tokenize_and_pad(review_text)\n        summary_tokens = self.tokenize_and_pad(summary_text)\n        \n        return {'input_ids': torch.tensor(review_tokens), 'labels': torch.tensor(summary_tokens)}\n    \n    def tokenize_and_pad(self, text):\n        tokens = self.tokenizer.encode(text, max_length=self.max_length, truncation=True)\n        padded_tokens = tokens[:self.max_length] + [0] * (self.max_length - len(tokens))\n        return padded_tokens\n\ndf = pd.read_csv(\"/kaggle/input/reviews/preprocessed_reviews.csv\")  \ntrain_df = df.sample(n=2000, random_state=42)  \n\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n\ntrain_dataset = CustomDataset(train_df, tokenizer, max_length=512)\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nmodel.train()\n\n#Hyperparameters\n\nnum_epochs = 5\noptimizer = AdamW(model.parameters(), lr = 1e-5)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=len(train_loader) * num_epochs)\n\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n        input_ids = batch['input_ids'].to(device)\n        labels = batch['labels'].to(device)\n        \n        outputs = model(input_ids=input_ids, labels=labels)\n        loss = outputs.loss\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()  \n        \n        total_loss += loss.item()\n    \n    avg_loss = total_loss / len(train_loader)\n    print(f\"Avg Loss: {avg_loss:.4f}\")\n\ntorch.save(model.state_dict(), \"./modelxx.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T20:46:54.544070Z","iopub.execute_input":"2024-04-30T20:46:54.544982Z","iopub.status.idle":"2024-04-30T21:14:43.170726Z","shell.execute_reply.started":"2024-04-30T20:46:54.544947Z","shell.execute_reply":"2024-04-30T21:14:43.169897Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nEpoch 1/5: 100%|██████████| 1000/1000 [05:32<00:00,  3.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.1079\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 1000/1000 [05:32<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0631\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 1000/1000 [05:32<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0612\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 1000/1000 [05:32<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0597\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 1000/1000 [05:32<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Avg Loss: 0.0581\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-30T19:22:45.998473Z","iopub.execute_input":"2024-04-30T19:22:45.998801Z","iopub.status.idle":"2024-04-30T19:22:59.081521Z","shell.execute_reply.started":"2024-04-30T19:22:45.998775Z","shell.execute_reply":"2024-04-30T19:22:59.080382Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelWithLMHead\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nfrom transformers import T5Tokenizer, GPT2Tokenizer\nfrom transformers import T5ForConditionalGeneration\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nmodel_name = \"t5-base\"\nimport pandas as pd\n\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\nmodul = T5ForConditionalGeneration.from_pretrained(model_name)\ntokanizer = T5Tokenizer.from_pretrained(model_name)\nmodel = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n\nfile_path = '/kaggle/input/reviews/preprocessed_reviews.csv'\ndf = pd.read_csv(file_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T22:29:46.799869Z","iopub.execute_input":"2024-04-30T22:29:46.800308Z","iopub.status.idle":"2024-04-30T22:29:52.290126Z","shell.execute_reply.started":"2024-04-30T22:29:46.800275Z","shell.execute_reply":"2024-04-30T22:29:52.289323Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1682: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference/Evaluation","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\nfrom rouge_score import rouge_scorer\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\ncustom_config = GPT2Config.from_pretrained(\"gpt2\", vocab_size=50257)\n\nmodel = GPT2LMHeadModel(custom_config)\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\nsaved_dict_path = \"/kaggle/input/modelxx/modelxx.pth\"\nstate_dict = torch.load(saved_dict_path)\nstate_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\nmodel.load_state_dict(state_dict)\n\ndef generate_summary(review_text, max_length=512):\n    inputs = tokenizer(review_text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=True)\n    outputs = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=max_length, num_beams=4, early_stopping=True)\n    summary = tokanizer.decode(outputs[0], skip_special_tokens=True)\n    summary = summary.replace('!', '')\n    return summary\n\nreview_text = input(\"Enter the review text: \")\n\nsummary = generate_summary(review_text)\nprint(\"Generated Summary:\", summary)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T22:31:45.213063Z","iopub.execute_input":"2024-04-30T22:31:45.213672Z","iopub.status.idle":"2024-04-30T22:32:01.371915Z","shell.execute_reply.started":"2024-04-30T22:31:45.213640Z","shell.execute_reply":"2024-04-30T22:32:01.371052Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the review text:  i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i end up try the apple and cinn find it to be very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith\n"},{"name":"stdout","text":"Generated Summary: i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate do not give you a chance to say no so i end up try the apple and cinn find it very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install rouge-score\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T19:23:45.240877Z","iopub.execute_input":"2024-04-30T19:23:45.241736Z","iopub.status.idle":"2024-04-30T19:23:59.818918Z","shell.execute_reply.started":"2024-04-30T19:23:45.241704Z","shell.execute_reply":"2024-04-30T19:23:59.817785Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=16b42c47e234380b33fcc879bc12e4f1301e8a4848dcda24e25ed09e6094c46c\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\nfrom rouge_score import rouge_scorer\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\ncustom_config = GPT2Config.from_pretrained(\"gpt2\", vocab_size=50257)\n\nmodel = GPT2LMHeadModel(custom_config)\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\nsaved_dict_path = \"/kaggle/input/models/fine_tuned_newmodel.pth\"\nstate_dict = torch.load(saved_dict_path)\nstate_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\nmodel.load_state_dict(state_dict)\n\ndef generate_summary(review_text, max_length=512):\n    inputs = tokenizer(review_text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=True)\n    outputs = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=max_length, num_beams=4, early_stopping=True)\n    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    summary = summary.replace('!', '')\n    return summary\n\ndef compute_rouge_scores(actual_summary, predicted_summary):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    scores = scorer.score(actual_summary, predicted_summary)\n    return scores\n\nreview_text = input(\"Enter the review text: \")\nactual_summary = input(\"Enter the actual summary text: \")\n\n# review_text = \"i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i end up try the apple and cinn find it to be very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith\"\n# actual_summary = \"good way to start the day\"\n\npredicted_summary = generate_summary(review_text)\n\nscores = compute_rouge_scores(actual_summary, predicted_summary)\n\nprint(\"Generated Summary:\", predicted_summary)\n\nprint(\"ROUGE-1: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge1'].precision, scores['rouge1'].recall, scores['rouge1'].fmeasure))\nprint(\"ROUGE-2: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge2'].precision, scores['rouge2'].recall, scores['rouge2'].fmeasure))\nprint(\"ROUGE-L: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rougeL'].precision, scores['rougeL'].recall, scores['rougeL'].fmeasure))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T21:30:37.070899Z","iopub.execute_input":"2024-04-30T21:30:37.071804Z","iopub.status.idle":"2024-04-30T21:31:19.586043Z","shell.execute_reply.started":"2024-04-30T21:30:37.071769Z","shell.execute_reply":"2024-04-30T21:31:19.585093Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Summary: i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i end up try the apple and cinn find it to be very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith\nROUGE-1: Precision: 0.04, Recall: 0.67, F1-Score: 0.08\nROUGE-2: Precision: 0.01, Recall: 0.20, F1-Score: 0.02\nROUGE-L: Precision: 0.04, Recall: 0.67, F1-Score: 0.08\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\nfrom rouge_score import rouge_scorer\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\ncustom_config = GPT2Config.from_pretrained(\"gpt2\", vocab_size=50257)\n\nmodel = GPT2LMHeadModel(custom_config)\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n\nsaved_dict_path = \"/kaggle/input/modelxx/modelxx.pth\"\nstate_dict = torch.load(saved_dict_path)\nstate_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n\nmodel.load_state_dict(state_dict)\n\ndef generate_summary(review_text, max_length=512):\n    inputs = tokenizer(review_text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=True)\n    outputs = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=max_length, num_beams=4, early_stopping=True)\n    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    summary = summary.replace('!', '')\n    return summary\n\ndef compute_rouge_scores(actual_summary, predicted_summary):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n    scores = scorer.score(actual_summary, predicted_summary)\n    return scores\n\nreview_text = input(\"Enter the review text: \")\nactual_summary = input(\"Enter the actual summary text: \")\n\n# review_text = \"i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i end up try the apple and cinn find it to be very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith\"\n# actual_summary = \"good way to start the day\"\n\npredicted_summary = generate_summary(review_text)\n\nscores = compute_rouge_scores(actual_summary, predicted_summary)\n\nprint(\"Generated Summary:\", predicted_summary)\nprint()\nprint(\"ROUGE-1: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge1'].precision, scores['rouge1'].recall, scores['rouge1'].fmeasure))\nprint(\"ROUGE-2: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rouge2'].precision, scores['rouge2'].recall, scores['rouge2'].fmeasure))\nprint(\"ROUGE-L: Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores['rougeL'].precision, scores['rougeL'].recall, scores['rougeL'].fmeasure))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T22:13:06.708008Z","iopub.execute_input":"2024-04-30T22:13:06.708708Z","iopub.status.idle":"2024-04-30T22:13:48.242649Z","shell.execute_reply.started":"2024-04-30T22:13:06.708673Z","shell.execute_reply":"2024-04-30T22:13:48.241711Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Summary: i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i end up try the apple and cinn find it to be very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith\n\nROUGE-1: Precision: 0.04, Recall: 0.67, F1-Score: 0.08\nROUGE-2: Precision: 0.01, Recall: 0.20, F1-Score: 0.02\nROUGE-L: Precision: 0.04, Recall: 0.67, F1-Score: 0.08\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nfrom rouge_score import rouge_scorer\n\nt5_model_name = \"t5-base\"\nt5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name)\nt5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n\ndef generate_summary_t5(review_text, max_length=512):\n    inputs = t5_tokenizer(\"summarize: \" + review_text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=True)\n    outputs = t5_model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=max_length, num_beams=4, early_stopping=True)\n    summary = t5_tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return summary\n\ndef compute_rouge_scores_t5(actual_summary, predicted_summary):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    scores = scorer.score(actual_summary, predicted_summary)\n    return scores\n\nreview_text = input(\"Enter the review text: \")\nactual_summary = input(\"Enter the actual summary text: \")\n\n# review_text = \"i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i end up try the apple and cinn find it to be very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith\"\n# actual_summary = \"good way to start the day\"\n\n# rev2= \"The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound,and feels comfortable to play. However, some users have reported issues with thetuning stability.\"\n# act2 = \"Good for beginners but has tuning stability issues.\"\n\npredicted_summary = generate_summary_t5(review_text)\n# predicted_summary = generate_summary_t5(rev2)\n\n\nscores_t5 = compute_rouge_scores_t5(actual_summary, predicted_summary)\n# scores_t5 = compute_rouge_scores_t5(act2, predicted_summary)\n\n\nprint(\"Generated Summary:\", predicted_summary)\n\nprint(\"ROUGE-1 : Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores_t5['rouge1'].precision, scores_t5['rouge1'].recall, scores_t5['rouge1'].fmeasure))\nprint(\"ROUGE-2 : Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores_t5['rouge2'].precision, scores_t5['rouge2'].recall, scores_t5['rouge2'].fmeasure))\nprint(\"ROUGE-L : Precision: {:.2f}, Recall: {:.2f}, F1-Score: {:.2f}\".format(scores_t5['rougeL'].precision, scores_t5['rougeL'].recall, scores_t5['rougeL'].fmeasure))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T21:53:19.943430Z","iopub.execute_input":"2024-04-30T21:53:19.943881Z","iopub.status.idle":"2024-04-30T21:53:57.820194Z","shell.execute_reply.started":"2024-04-30T21:53:19.943849Z","shell.execute_reply":"2024-04-30T21:53:57.819226Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generated Summary: summarize: i be visit my friend nate the other morning for coffee he come out of his storage room with a packet of mccanns instant irish oatmeal he suggest that i try it for my own use in my stash sometimes nate dose not give you a chance to say no so i end up try the apple and cinn find it to be very tastefull when make with water or powder milk it go good with oj and coffee and a slice of toast and your ready to take on the worldor the day at least jerry reith\nROUGE-1 : Precision: 0.04, Recall: 0.67, F1-Score: 0.08\nROUGE-2 : Precision: 0.01, Recall: 0.20, F1-Score: 0.02\nROUGE-L : Precision: 0.04, Recall: 0.67, F1-Score: 0.08\n","output_type":"stream"}]}]}